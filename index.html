<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Workshop on the Future of Computing Architectures (FOCA 2020)</title>

    <!-- css -->
    <link rel="stylesheet" href="bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="bower_components/ionicons/css/ionicons.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
	<style>
		.popover {
		        max-width: 80% !important;
		    }
	</style>
</head>
<body data-spy="scroll" data-target="#site-nav">
    <nav id="site-nav" class="navbar navbar-fixed-top navbar-custom">
        <div class="container">
            <div class="navbar-header">

                <!-- logo -->
                <div class="site-branding">
                    <a class="logo" href="index.html">
                        
                        <!-- logo image  -->
                        <!-- <img src="assets/images/logo.png" alt="Logo"> -->
                        FOCA 2020
                    </a>
                </div>

                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-items" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

            </div><!-- /.navbar-header -->

            <div class="collapse navbar-collapse" id="navbar-items">
                <ul class="nav navbar-nav navbar-right">

                    <!-- navigation menu -->
                    <li class="active"><a data-scroll href="#about">About</a></li>
                    <li><a data-scroll href="#speakers">Speakers</a></li>                  
                    <li><a data-scroll href="#program">Program</a></li>                  
                    <li><a data-scroll href="#org">Organizers</a></li>                  
                
                </ul>
            </div>
        </div><!-- /.container -->
    </nav>

    <header id="site-header" class="site-header valign-center"> 
        <div class="intro">

            <p>October 30<sup>th</sup> 2020 &mdash; "Virtual Edition"</p>
            
            <h1 class="display-1">FOCA 2020</h1>
            <h1>5<sup>th</sup> Workshop on the Future of Computing Architectures</h1>
            
            <p>IBM Research</p>
            
            <!--
            <a class="btn btn-white" data-scroll href="#about">Contribute Now</a>

            <a class="btn btn-white" data-scroll href="#registration">Register Now</a>
            -->
        
        </div>
    </header>

    <section id="about" class="section about">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <h3 class="section-title">About</h3>
                    
                    <p>
                    The <b>5<sup>th</sup> Workshop on the Future of Computing Architectures (FOCA 2020)</b> will be held on Friday October 
                    30th, 2020 <strong>in a virtual format</strong>. This event is a full-day workshop  that provides a forum for invited
					students in a broad range of fields covering all aspects of architectures for the  future of computing. Invited students
					are expected to showcase their work and interact with their peers and members of  the IBM Research community.<br><br>

                    The topics covered by FOCA 2020 include but are not limited to:
                    
                    <ul class="list-arrow-right">
                        <li>Architectures for artificial intelligence / machine learning.</li>
                        <li>Security- and reliability-aware architectures.</li>
                        <li>Architectures for cloud, high-performance computing, and data centers.</li>
                        <li>Next-generation memory architectures.</li>
                        <li>Parallel architectures.</li>
                        <li>Power‐efficient architectures and systems.</li>
                        <li>Embedded, IoT, reconfigurable, and heterogeneous architectures.</li>
                        <li>Architectures for emerging technology and applications.</li>
                        <li>Quantum computing, quantum circuit optimization.</li>
                    </ul>
                    
                    <br>

                    <h3 class="section-title">Past Editions</h3>
                        
                    <ul class="list-arrow-right">
                        <li><a href="https://augustojv.github.io/foca-workshop-2019" target="_blank">2019</a></li>
                        <li><a href="https://researcher.watson.ibm.com/researcher/view_group.php?id=9671" target="_blank">2018</a></li>
                        <li><a href="https://researcher.watson.ibm.com/researcher/view_group.php?id=8187" target="_blank">2017</a></li>
                        <li><a href="http://researcher.watson.ibm.com/researcher/view_group.php?id=7424" target="_blank">2016</a></li>
                    </ul>

                    <br>
                    
                    <h3 class="section-title">Contact</h3>
                        
                    <ul class="list-arrow-right">
                    <li><a href="mailto:info@foca-workshop.org">info@foca-workshop.org</a></li> 
                    </ul>

                </div><!-- /.col-sm-6 -->

                <div class="col-sm-6">

                    <h3 class="section-title multiple-title">Organizing Committee</h3>
                    <p>
					<ul class="list-arrow-right">
                        <li>Augusto Vega</li>
                        <li>Karthik Swaminathan</li>
                        <li>Xinyu Que</li>
					</ul>
                    </p>

                    <h3 class="section-title multiple-title">Selection Committee</h3>
                    <p>
					<ul class="list-arrow-right">
						<li>Alper Buyuktosunoglu</li>
						<li>Anne Gattiker</li>
						<li>Bishwaranjan Bhattacharjee</li>
						<li>Bulent Abali</li>
						<li>Charles Lefurgy</li>
						<li>Hubertus Franke</li>
						<li>Jeff Stuecheli</li>
						<li>Jinjun Xiong</li>
						<li>John-David Wellman</li>
						<li>Kaoutar el Maghraoui</li>
						<li>Leopold Grinberg</li>
						<li>Manoj Kumar</li>
						<li>Mihir Choudhury</li>
						<li>Nagu Dhanwada</li>
						<li>Nandhini Chandramoorthy</li>
						<li>Ravi Nair</li>
						<li>Sai Zeng</li>
						<li>Sandhya Koteshwara</li>
						<!--<li>Schuyler Eldridge</li>-->
						<li>Swagath Venkataramani</li>
						<li>Talia Gershon</li>
					</ul>
                    </p>


                </div><!-- /.col-sm-6 -->
            </div><!-- /.row -->
        </div><!-- /.container -->
    </section>

    <section id="links" class="section bg-image-2 facts ">
        <div class="container">
            <div class="row">
				<div class="col-md-12">
                    <h3 class="section-title">Interesting Links</h3>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://www.computerhistory.org/timeline/ai-robotics/" rel="nofollow" target="_blank">AI and Robotics Timeline</a> from 1939 to date.</p>
                </div><div class="col-md-3">
                    <p>The <a href="https://www.research.ibm.com/ibm-q/technology/experience/" rel="nofollow" 
                        target="_blank">IBM Q Experience</a> to try a quantum computer online.</p>
                </div><div class="col-md-3">
                    <p>IBM Watson in action in this <a href="https://visual-recognition-demo.mybluemix.net" rel="nofollow" target="_blank">on-line demo</a> using deep learning.</p>
                </div><div class="col-md-3">
                    <p>The <a href="http://research.ibm.com/cognitive-computing/" rel="nofollow" target="_blank">AI Portal</a> with the latest IBM research activities.</p>
                </div>


        </div>
    </section>

    <section id="speakers" class="section speakers">
        <div class="container">
            <div class="row">
                <div class="col-md-12">

                    <h3 class="section-title">Invited Speakers (Regular Presentations)</h3>
                
                </div>
            </div>

            <div class="row">
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Lauren_Biernacki.png">
                        </figure>

                        <h4>Lauren Biernacki</h4>
                        <p>University of Michigan</p>
                    </div>
                </div>

                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Ghada_Dessouky.png">
                        </figure>

                        <h4>Ghada Dessouky</h4>
                        <p>Technical University of Darmstadt</p>
                    </div>
                </div>

                <div class="col-md-3">
                    <div class="speaker">

                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Leila_Delshadtehrani.png">
                        </figure>

                        <h4>Leila Delshadtehrani</h4>
                        <p>Boston University</p>

                    </div>
                </div>

                <div class="col-md-3">
                    <div class="speaker">

                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Thierry_Tambe.png">
                        </figure>

                        <h4>Thierry Tambe</h4>
                        <p>Harvard University</p>

                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-md-4">

                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Ashutosh_Dhar.png">
                        </figure>

                        <h4>Ashutosh Dhar</h4>
                        <p>University of Illinois,<br>Urbana-Champaign</p>
                    </div>
                </div>
                <div class="col-md-4">

                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/placeholder.png">
                        </figure>

                        <h4>Daniel Richins</h4>
                        <p>University of Texas,<br>Austin</p>
                    </div>
                </div>
				<!--
                <div class="col-md-3">

                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Ikenna_Okafor.png">
                        </figure>

                        <h4>Ikenna Okafor</h4>
                        <p>Penn State University</p>
                    </div>
                </div>
				-->
                <div class="col-md-4">

                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/Naorin_Hossain.png">
                        </figure>

                        <h4>Naorin Hossain</h4>
                        <p>Princeton University</p>
                    </div>
                </div>
            </div>
				
        </div>
    </section>

    <section id="program" class="section schedule">

        <div class="container">
            <div class="row">
                <div class="col-md-11">
                    <h3 class="section-title">Program</h3>
					(<em>all times are in Eastern Time</em>)
                    <p>
                    <table class="table table-hover">
                      <thead class="thead-light">
                        <tr>
                          <th colspan=2 scope="col">Friday October 30<sup>th</sup>, 2020</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th scope="row">8:50 - 9:00am</th>
                          <td>Introduction and Welcoming Remarks</td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">9:00 - 10:00am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  Seelam leads a worldwide team to define the strategy and implement the execution plan for accelerators (GPUs, Quantum and Disaggregation) and HPC on IBM 
						  Hybrid Cloud. This team is a group of world class researchers and engineerings with deep expertise in accelerators and HPC. Seelam drives the innovation 
						  roadmap that spans multiple generations of compute, network, storage, accelerators, resource scheduling for large scale applications in a geographically 
						  distributed cloud system. In this talk, Seelam will describe the team's latest work in this space and discuss open research problems.
						  ">
							  <strong>Keynote: "Future of Compute Accelerators in the Cloud"</strong><br>
						      Seetharami Seelam (IBM Research)</td>
                        </tr>
                        <tr>
                          <th scope="row">10:00 - 10:30am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  Modern multi-core processors suffer from an inherent performance-security conflict with respect to their continuously evolving performance optimizations. One 
						  prominent example is how they share cache resources for maximum cache utilization and performance gains. This leave the cache vulnerable to side-channel 
						  attacks, where inherent timing differences in shared cache behavior are exploited to infer information on the victim’s execution patterns, ultimately leaking 
						  private information such as a secret key. The root causes for these attacks is mutually distrusting processes sharing the cache entries and accessing them in 
						  a deterministic and consistent set-associative manner. While various defenses against cache side-channel attacks have been proposed, they continue to suffer 
						  from serious shortcomings. More importantly, they rigidly assume that side-channel-resilient caches are required for the entire execution workload and do not 
						  allow the possibility to selectively enable the mitigation only for the security-critical portion of the workload.<br>
						  In this talk, we discuss our insights on such attacks, and the need for a new hardware design paradigm that considers customizable security as a design 
						  metric, and not an afterthought. We present a mechanism for a flexible and soft partitioning of set-associative caches and propose hybrid cache architectures 
						  that can be configured to selectively apply side-channel-resilient cache behavior only for isolated execution domains, while providing the non-isolated 
						  execution with conventional cache behavior, capacity and performance.  We show how this can be achieved with minimal performance and area overheads, while 
						  effectively mitigating typical access-based and contention-based cache attacks.
						  ">
						  	  "HybCache: Hybrid Side-Channel-Resilient Caches for Trusted Execution Environments"<br>
                              Ghada Dessouky (Technical University of Darmstadt)
						  </td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">10:30 - 10:45am</th>
                          <td><i>Break</i></td>
                        </tr>

                        <tr>
                          <th scope="row">10:45 - 11:15am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  We unveil a set of algorithm-hardware-silicon co-designs to demonstrate computationally accurate and noise-robust speech-to-text and natural language 
						  processing (NLP) inference. First, we propose a novel floating-point inspired number format, AdaptivFloat, that dynamically maximizes and optimally clips its 
						  available dynamic range, at a layer granularity, in order to create faithful encodings of neural network parameters. AdaptivFloat consistently produces higher 
						  inference accuracies compared to block floating-point, uniform, IEEE-like float and posit encodings at low bit precision (≤8-bit) across a diverse set of 
						  state-of-the-art neural networks, exhibiting narrow to wide weight distribution. Second, we make the case for Bayesian-based speech enhancement for efficient 
						  and noise-robust speech recognition in acoustically challenged environments with multiple moving sound sources. Third, we describe FlexNLP, a flexible and 
						  programmable hardware accelerator optimized for efficient acceleration of bidirectional attention-based, sequence-to-sequence (seq2seq) networks commonly used 
						  in multi-task NLP inference. Finally, we validate the above-mentioned techniques in 16nm chip tapeouts, with competitive and leading-edge metrics.
						  ">
							  "Algorithms, Architectures and Prototypes for Accurate and Noise-Robust Speech and Natural Language<br>
							  Processing Inference"<br>
                              Thierry Tambe (Harvard University)</td>
                        </tr>
                        <tr>
                          <th scope="row">11:15 - 11:45am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  Artificial intelligence and machine learning are experiencing widespread adoption in industry, academia, and even public consciousness.  This has been driven 
						  by rapid advances in the applications and accuracy of AI through increasingly complex algorithms and models; this, in turn, has spurred research into 
						  specialized hardware AI accelerators.  Given the rapid pace of advances, it is easy to forget that these advances are often developed and evaluated in a 
						  vacuum without considering the full application environment.  In this talk, I emphasize the need for holistic, end-to-end analysis of AI workloads and discuss 
						  the “AI tax”: the supporting compute, infrastructure, and cost associated with running AI applications.  To this end, I present and describe Face Recognition, 
						  an AI-centric, edge data center, video analytics application built using popular open source infrastructure and ML tools.  Despite using state-of-the-art AI 
						  and ML algorithms, the application relies heavily on pre- and post-processing code, which constitute a large part of the AI tax.  As AI-centric applications 
						  benefit from the acceleration promised by accelerators, they will impose stresses on the hardware and software infrastructure: storage and network bandwidth 
						  become major bottlenecks with increasing AI acceleration.  By specializing for AI applications, a purpose-built edge data center can be designed for the 
						  stresses of accelerated AI at 15% lower TCO than one derived from homogeneous servers and infrastructure.
						  ">
							  "AI Tax: The Hidden Cost of AI Data Center Applications"<br>
                              Daniel Richins (University of Texas at Austin)</td>
                        </tr>
						<!--
                        <tr>
                          <th scope="row">11:45am - 12:15pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  The demand for Visual analytic solutions continues to increase. New classes of applications are emerging that integrate processing copious volumes of data at 
						  high bit rates. Moreover, contemporary data transfer rates can become a bottleneck for latency-sensitive workloads. These workloads pose a challenge for 
						  traditional DNN accelerator platforms which run solely in the cloud. To this end a DNN hardware accelerator capable of running on a distributed platform is 
						  presented. This accelerator can map a DNN’s topology to hardware per layer and process input maps and kernels over multiple iterations. The context of each 
						  iteration can be spread over multiple heterogenous compute fabrics for efficient distributed execution. Furthermore, we show that the architecture supports a 
						  configurable number of processing elements which can be amended for both high end cloud devices, and resource constrained embedded platforms.
						  ">
							  "Distributed Inference for Video Analytics Applications"<br>
                              Ikenna Okafor (Penn State University)</td>
                        </tr>
						-->
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">11:45am - 1:00pm</th>
                          <td><i>Lunch Break</i></td>
                        </tr>
                        <tr>
                          <th scope="row">1:00 - 1:30pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  With the increased dependence on cloud computing services, data privacy has become a significant societal concern. Critical applications take advantage of 
						  vast computing resources in the cloud to process and store personal data; however, the confidentiality of this data is not guaranteed. Traditional techniques 
						  for data privacy in cloud computing encrypt client data during transmission and while at rest on remote servers. When these two techniques are in place, 
						  private data still exists as plaintext within the system. Thus, confidentiality is only ensured if these plaintext values are inaccessible, requiring the 
						  remote server to be impenetrable. As evidenced by the continual security arms race, this cannot be confidently achieved.<br>
						  Recent advances in privacy technology enable us to protect data within the system itself. Two approaches reign supreme when it comes to protecting data during 
						  computation: secure enclaves and fully homomorphic encryption. However, these runtime techniques are not absolute. Homomorphic encryption is ideal for 
						  outsourced, privacy-preserving computation, as computation can be performed without access to secret keys or plaintext values. For this reason, homomorphic 
						  encryption has been touted as the holy grail of data privacy. But, although advancements in homomorphic encryption are developing rapidly, the scheme’s poor 
						  performance and challenging programming environment make it impractical for use in many potential applications. A practical alternative to homomorphic 
						  encryption is secure hardware enclaves, such as Intel SGX and ARM TrustZone. These technologies enforce data privacy with system and hardware support. 
						  However, state-of-the-art enclaves have two major design flaws that leave them vulnerable to penetration; they include software components that render 
						  sensitive values vulnerable to attackers, and they share hardware resources with untrusted processes that can use side-channel attacks to exfiltrate sensitive 
						  data.<br>
						  In this work, we aim to advance microprocessor enclaves forward to the point where they are not only as powerful as homomorphic encryption, but also as 
						  efficient and programmable as secure enclaves. Our hardware enclave leverages sequestered encryption to fix the two problems with the existing 
						  state-of-the-art. Our design removes all software from the enclave, and sequesters all decrypted data and secret keys away from storage accessible by 
						  software, preventing the side-channel attacks that have plagued Intel SGX and ARM TrustZone. Furthermore, by using traditional architecture techniques, our 
						  approach can be significantly faster than fully homomorphic encryption, much more programmable, and is amenable to time-tested cryptographic-algorithms. With 
						  our prototype implementation, we hope to demonstrate a comprehensive privacy-preserving architecture that balances performance, security, and trust.
						  ">
							  "Can Hardware Enclaves Be as Powerful as Homomorphic Encryption?"<br>
                              Lauren Biernacki (University of Michigan)</td>
                        </tr>
                        <tr>
                          <th scope="row">1:30 - 2:00pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  In recent years, security breaches of computing systems have become very common; hence, designing secure computing systems has become a first-class 
						  requirement. Typically software solutions are the main defense mechanism against security attacks, but due to their high performance overhead not all 
						  solutions get readily adopted. To lower this overhead, in the past few years, there has been a growing trend in the computing industry to enforce security 
						  policies in the processor hardware, e.g., Intel MPX and Intel CET. However, developing dedicated hardware security extensions is an imperfect, lengthy, and 
						  costly process. In contrast to fixed hardware extensions for security, a programmable hardware monitor can efficiently enforce and enhance a variety of 
						  security policies as security threats evolve. Such a flexible hardware solution enables software developers to implement various security policies in hardware 
						  without the need to understand the underlying architecture. In this talk, I present our work on an efficient and minimally-invasive implementation of a 
						  programmable hardware monitor, called PHMon, and the full Linux-based software stack around it. Then, I will present some of PHMon’s practical security use 
						  cases evaluated on an FPGA prototype.
						  ">
							  "Towards Programmable Hardware Monitors for Security"<br>
                              Leila Delshadtehrani (Boston University)</td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">2:00 - 2:15pm</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr>
                          <th scope="row">2:15 - 2:45pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  The need for higher energy efficiency has resulted in the proliferation of accelerators across platforms, with custom and reconfigurable accelerators adopted 
						  in both edge devices and cloud servers. However, existing  solutions fall short in providing accelerators with low-latency, high-bandwidth access to the 
						  working set and suffer from the high latency and energy cost of data transfers. Such costs can severely limit the smallest granularity of the tasks that can 
						  be accelerated and thus the applicability of the accelerators.<br>
						  In this work, I will present FReaC Cache, a novel architecture that natively supports reconfigurable computing in the last level cache (LLC), thereby giving 
						  energy-efficient accelerators low-latency, high-bandwidth access to the working set.<br>
						  By leveraging the cache's existing dense memory arrays, buses, and logic folding, we construct a reconfigurable fabric in the LLC with minimal changes to the 
						  system, processor, cache, and memory architecture. FReaC Cache is a low-latency, low-cost, and low-power alternative to off-die/off-chip accelerators, and a 
						  flexible, and low-cost alternative to fixed function accelerators. We demonstrate an average speed up of 3X and Perf/W improvements of 6.1X  over an 
						  edge-class multi-core CPU, and add 3.5% to 15.3% area overhead per cache slice.<br>
						  FReaC Cache will appear this October, at the 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), 2020.
						  ">
							  "FReaC Cache: Folded-Logic Reconfigurable Computing in the Last Level Cache"<br>
                              Ashutosh Dhar (University of Illinois at Urbana-Champaign)</td>
                        </tr>
                        <tr>
                          <th scope="row">2:45 - 3:15pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="
						  Memory consistency models (MCMs) have been formulated as a mechanism for expressing the legal ordering and visibility of shared memory accesses in hardware 
						  and software. They are fundamental for ensuring heterogeneous components of a system execute and interact as expected to prevent hardware-induced bugs in 
						  real-world programs. However, ISA-level MCMs are limited to defining the behavior of only user-facing assembly instructions and do not account for virtual 
						  memory implementations that may result in the execution of 1) hardware-level state updates and 2) system-level interactions. Both are capable of accessing 
						  memory and may affect program outcomes, thus making them software-visible. As a result, memory transistency models (MTMs) have been coined as a superset of 
						  MCMs to additionally capture and enforce virtual memory-aware ordering rules. However, no prior work enabled the formal specification or analysis of MTMs.<br>
						  TransForm fills this gap by introducing an axiomatic vocabulary for formally specifying MTMs that builds on the standard axiomatic vocabulary traditionally 
						  used for describing MCMs. It provides new constructs for modeling transistency-specific features such as hardware-level state updates and system-level 
						  interactions. Using this new axiomatic vocabulary, MTMs can be formally specified and used with TransForm’s synthesis engine to synthesize litmus tests 
						  enhanced with transistency features, called enhanced litmus tests. This talk will cover TransForm’s axiomatic vocabulary and synthesis engine, as well as a 
						  case study performed with TransForm to formally define an approximate MTM for Intel x86 processors.
						  ">
							  "TransForm: Formally Specifying Transistency Models and Synthesizing Enhanced Litmus Tests"<br>
                              Naorin Hossain (Princeton University)</td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">3:15 - 3:30pm</th>
                          <td><i>Break</i></td>
                        </tr>						
                        <tr>
                          <th scope="row">3:30 - 4:45pm</th>
                          <td><strong>Lightning talks:</strong><br>
                              &bull; "Bit Error Robustness for Energy-Efficient DNN Accelerators"<br>
							  &nbsp;&nbsp; David Stutz (Max Planck Institute for Informatics, Germany)<br>
                              &bull; "Waferscale Processors: The Chiplet Approach"<br>
							  &nbsp;&nbsp; Saptadeep Pal (University of California, Los Angeles)<br>
							  &bull; "Symphony: A Framework for Intelligence Augmented Heterogenous Computing Systems"<br>
							  &nbsp;&nbsp; Subho Sankar Banerjee (University of Illinois at Urbana-Champaign)<br>
							  &bull; "Scalable Systolic Array Architecture (SSAA) &mdash; a General Convolutional Neural Network ISA and<br>
							  &nbsp;&nbsp; Compiler-Enabled Dataflow to Maximize Parallelism While Reducing Memory Utilization"<br>
							  &nbsp;&nbsp; Cesar Lopez-Carrasco (Texas A&M University)<br>
							  &bull; "LUTNet: Rethinking Inference in FPGA Soft Logic"<br>
							  &nbsp;&nbsp; Erwei Wang (Imperial College, London)<br>
							  &bull; "Mitigating Set-Conflict Based Cache Attacks with a Practical Fully-Associative Design"<br>
							  &nbsp;&nbsp; Gururaj Saileshwar (Georgia Institute of Technology)<br>
							  &bull; "A Low-Power, High-Throughput Microarchitecture for Long Short-Term Memory (LSTM) Neural Network Computation"<br>
							  &nbsp;&nbsp; Qianli Zhao (North Carolina State University)<br>
							  &bull; "Graph Analytics Accelerator Supporting Sparse Data Representation Using Crossbar Architectures"<br>
							  &nbsp;&nbsp; Nagadastagiri (Naga) Challapalle (Penn State University)<br>
							  &bull; "Compliance Aware Hybrid Scheduling"<br>
							  &nbsp;&nbsp; Nerla Jean-Louis (University of Illinois at Urbana-Champaign)<br><br>
							  <strong>Open Q&A for lightning talks (30 mins)</strong>
						  </td>
                        </tr>
                        <tr>
                          <th scope="row">4:45pm</th>
                          <td>Concluding Remarks</td>
                        </tr>
                      </tbody>
                    </table>
                    </p>
                </div>
            </div>
    </section>

    <section id="org" class="section registration">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Organizers</h3>
                </div>
                <div class="col-md-8">
                <p>
                <b><a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-ajvega" rel="nofollow" target="_blank">Augusto 
                    Vega</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center involved in research and development work in 
                    the areas of highly-reliable power-efficient embedded designs, cognitive systems and mobile computing. He holds M.S. and 
                    Ph.D. degrees from Polytechnic University of Catalonia (UPC), Spain.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-kvswamin" rel="nofollow" 
                    target="_blank">Karthik Swaminathan</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center. His research 
                    interests include power-aware architectures, domain-specific accelerators and emerging device technologies in processor 
                    design. He is also interested in architectures for approximate and cognitive computing, particularly in aspects related 
                    to their reliability and energy efficiency. He holds a Ph.D. degree from Penn State University.
                </p>
                <p>
                <b><a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-xque" rel="nofollow" target="_blank">Xinyu 
                    Que</a> </b> is a Research Staff Member in the Data Centric Systems Co-Design department at the T. J. Watson Research 
                    Center. He received his M.S. degree in Computer Science and Engineering from University of Connecticut and Ph.D. 
                    degrees in Computational Science and Software Engineering from Auburn University. Xinyu has broad interests in high 
                    performance computing and large-scale graph analytics.
                </p>
                </div>
            </div>
        </div>
    </section>

    <footer class="site-footer facts">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <p class="site-info">Share this event on your social networks</p>
                </div>
                <div class="col-md-4">
                    <a href="https://twitter.com/home?status=Check%20out%20the%20Workshop%20on%20the%20Future%20of%20Computing%20Architectures%0Ahttps%3A//foca-workshop.org" rel="nofollow" target="_blank"><i class="ion-social-twitter"></i>&nbsp; Twitter</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//foca-workshop.org/" rel="nofollow" target="_blank"><i class="ion-social-facebook"></i>&nbsp; Facebook</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//foca-workshop.org/&title=Workshop%20on%20the%20Future%20of%20Computing%20Architectures&summary=&source=" rel="nofollow" target="_blank"><i class="ion-social-linkedin-outline"></i>&nbsp; LinkedIn</a>
                </div>
            </div>
        </div>
    </footer>

    <!-- script -->
    <script src="bower_components/jquery/dist/jquery.min.js"></script>
    <script src="bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="bower_components/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
    <script src="assets/js/main.js"></script>
	<script>
	$(document).ready(function(){
		$('[data-toggle="popover"]').popover({
			trigger : 'hover',
			title: 'Abstract',
			html    : true
		});		
	});
	</script>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88908704-1', 'auto');
  ga('send', 'pageview');

</script>
  
</html>
